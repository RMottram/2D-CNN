{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import figure\n",
    "import pandas as pd\n",
    "import sys, os, time, csv, glob, cv2\n",
    "\n",
    "os.environ[\"KERAS_BACKEND\"] = \"plaidml.keras.backend\"\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPooling2D, AveragePooling2D\n",
    "from keras import backend as K\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "\n",
    "import sklearn\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn import metrics\n",
    "\n",
    "## Settings\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.options.display.float_format = '{:.5f}'.format\n",
    "np.set_printoptions(threshold=sys.maxsize)\n",
    "np.set_printoptions(precision = 5, suppress = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_normal = []\n",
    "train_attack = []\n",
    "test_normal = []\n",
    "test_attack = []\n",
    "\n",
    "for i in glob.glob('/Users/ryan/NSL CNN/2d-cnn/split_images/64x64/80-20/train_normal/train_normal_equ_*.jpg', recursive=True):\n",
    "    train_normal.append(cv2.imread(i, cv2.IMREAD_GRAYSCALE))\n",
    "\n",
    "for j in glob.glob('/Users/ryan/NSL CNN/2d-cnn/split_images/64x64/80-20/train_attack/train_attack_equ_*.jpg', recursive=True):\n",
    "    train_attack.append(cv2.imread(j, cv2.IMREAD_GRAYSCALE))\n",
    "\n",
    "for k in glob.glob('/Users/ryan/NSL CNN/2d-cnn/split_images/64x64/80-20/test_normal/test_normal_equ_*.jpg', recursive=True):\n",
    "    test_normal.append(cv2.imread(k, cv2.IMREAD_GRAYSCALE))\n",
    "\n",
    "for l in glob.glob('/Users/ryan/NSL CNN/2d-cnn/split_images/64x64/80-20/test_attack/test_attack_equ_*.jpg', recursive=True):\n",
    "    test_attack.append(cv2.imread(l, cv2.IMREAD_GRAYSCALE))\n",
    "\n",
    "train_normal = np.array(train_normal)\n",
    "train_attack = np.array(train_attack)\n",
    "test_normal = np.array(test_normal)\n",
    "test_attack = np.array(test_attack)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1714, 64, 64), (1576, 64, 64), (429, 64, 64), (394, 64, 64))"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(train_normal), np.shape(train_attack), np.shape(test_normal), np.shape(test_attack)\n",
    "\n",
    "# for i in range(0, 2):\n",
    "#   plt.imshow(train_normal[i], cmap = 'gray')\n",
    "#   plt.show()\n",
    "\n",
    "# for i in train_normal:\n",
    "#   print(i)\n",
    "\n",
    "\n",
    "## MORE NORMAL DATA FOR TESTING TO GET SAME RATIO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pxl_tot = []\n",
    "\n",
    "for i in range(0, train_normal.shape[0]):\n",
    "    pxl_avg = train_normal[i].sum() / 4096\n",
    "    pxl_tot.append(pxl_avg)\n",
    "#     print(f'Image {i}: {pxl_avg}')\n",
    "    print(sum(pxl_tot)/4096)\n",
    "    \n",
    "#     if train_normal[i].sum() / 255 <= 3125:\n",
    "#         plt.imshow(train_normal[i], cmap = 'gray')\n",
    "#         plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_transition = []\n",
    "test_transition = []\n",
    "\n",
    "for i in range(0, train_attack.shape[0]):\n",
    "    if train_attack[i].sum() / 4096 < 6:\n",
    "        train_transition.append(train_attack[i])\n",
    "\n",
    "for j in range(0, train_normal.shape[0]):\n",
    "    if train_normal[j].sum() / 4096 < 6:\n",
    "        train_transition.append(train_normal[j])\n",
    "\n",
    "for k in range(0, test_attack.shape[0]):\n",
    "    if test_attack[k].sum() / 4096 < 6:\n",
    "        test_transition.append(test_attack[k])\n",
    "        \n",
    "for l in range(0, test_normal.shape[0]):\n",
    "    if test_normal[l].sum() / 4096 < 6:\n",
    "        test_transition.append(test_normal[l])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transition = np.array(train_transition)\n",
    "test_transition = np.array(test_transition)\n",
    "train_transition.shape, test_transition.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## augmenting the data to create more images\n",
    "## only run cell if needed\n",
    "\n",
    "## vertically flip training images\n",
    "vert_flip_train_attack = np.fliplr(train_attack)\n",
    "vert_flip_train_normal = np.fliplr(train_normal)\n",
    "\n",
    "## flip training images horizonatally\n",
    "hor_flip_train_attack = np.rot90(train_attack, axes = (1,2), k = 2)\n",
    "hor_flip_train_normal = np.rot90(train_normal, axes = (1,2), k = 2)\n",
    "\n",
    "## rotate training images left and right once each\n",
    "rotate90l_train_attack = np.rot90(train_attack, axes=(1, 2))\n",
    "rotate90r_train_attack = np.rot90(train_normal, -1, axes=(1, 2))\n",
    "rotate90l_train_normal = np.rot90(train_attack, axes=(1, 2))\n",
    "rotate90r_train_normal = np.rot90(train_normal, -1, axes=(1, 2))\n",
    "\n",
    "\n",
    "\n",
    "## vertically flip testing images\n",
    "vert_flip_test_attack = np.fliplr(test_attack)\n",
    "vert_flip_test_normal = np.fliplr(test_normal)\n",
    "\n",
    "## flip testing images horizonatally\n",
    "hor_flip_test_attack = np.rot90(test_attack, axes = (1,2), k = 2)\n",
    "hor_flip_test_normal = np.rot90(test_normal, axes = (1,2), k = 2)\n",
    "\n",
    "## rotate testing images left and right once each\n",
    "rotate90l_test_attack = np.rot90(test_attack, axes=(1, 2))\n",
    "rotate90r_test_attack = np.rot90(test_normal, -1, axes=(1, 2))\n",
    "rotate90l_test_normal = np.rot90(test_attack, axes=(1, 2))\n",
    "rotate90r_test_normal = np.rot90(test_normal, axes=(1, 2))\n",
    "\n",
    "\n",
    "## stack all the original and augmented data to one single numpy array\n",
    "train = np.vstack((train_attack, vert_flip_train_attack, hor_flip_train_attack, rotate90l_train_attack, rotate90r_train_attack,\n",
    "                   train_normal, vert_flip_train_normal, hor_flip_train_normal, rotate90l_train_normal, rotate90r_train_normal))\n",
    "test = np.vstack((test_attack, vert_flip_test_attack, hor_flip_test_attack, rotate90l_test_attack, rotate90r_test_attack,\n",
    "                  test_normal, vert_flip_test_normal, hor_flip_test_normal, rotate90l_test_normal, rotate90r_test_normal))\n",
    "\n",
    "## without rotate data\n",
    "# train = np.vstack((train_attack, vert_flip_train_attack, hor_flip_train_attack,\n",
    "#                    train_normal, vert_flip_train_normal, hor_flip_train_normal))\n",
    "# test = np.vstack((test_attack, vert_flip_test_attack, hor_flip_test_attack,\n",
    "#                   test_normal, vert_flip_test_normal, hor_flip_test_normal, rotate90l_test_normal, rotate90r_test_normal))                  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## if no augmented data is needed, run this cell\n",
    "train = np.vstack((train_attack, train_normal))\n",
    "test = np.vstack((test_attack, test_normal))\n",
    "\n",
    "train.shape, test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train.reshape(-1,64,64,1)\n",
    "test = test.reshape(-1,64,64,1)\n",
    "train_transition = train_transition.reshape(-1,64,64,1)\n",
    "test_transition = test_transition.reshape(-1,64,64,1)\n",
    "\n",
    "train.shape, test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0, 5):\n",
    "    plt.imshow(train[i], cmap = 'gray')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Number of training images: {train.shape[0]}\\nNumber of testing images {test.shape[0]}\\n')\n",
    "print(f'Number of training attack: {train_attack.shape[0]}\\nNumber of vert flip train attack: {vert_flip_train_attack.shape[0]}\\nNumber of training normal: {train_normal.shape[0]}\\nNumber of vert flip training normal: {vert_flip_train_normal.shape[0]}\\n')\n",
    "\n",
    "print(f'Number of testing attack: {test_attack.shape[0]}\\nNumber of vert flip test attack: {vert_flip_test_attack.shape[0]}\\nNumber of hor flip test attack: {hor_flip_test_attack.shape[0]}\\nNumber of test normal: {test_normal.shape[0]}\\nNumber of vert flip test normal: {vert_flip_test_normal.shape[0]}\\n' +\n",
    "    f'Number of hor flip test normal: {hor_flip_test_normal.shape[0]}\\nNumber of rotate90 left test normal: {rotate90l_test_normal.shape[0]}\\nNumber of rotate90 right test normal: {rotate90r_test_normal.shape[0]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## create the training and testing data labels\n",
    "## run if not using augmented data\n",
    "\n",
    "training_labels = []\n",
    "## add the attack labels\n",
    "for i in range(0, train_attack.shape[0]):\n",
    "    training_labels.append('attack')\n",
    "\n",
    "## add the normal labels\n",
    "for j in range(train_attack.shape[0], train.shape[0]):\n",
    "    training_labels.append('normal')\n",
    "\n",
    "\n",
    "\n",
    "testing_labels = []\n",
    "## add the attack labels\n",
    "for k in range(0, test_attack.shape[0]):\n",
    "    testing_labels.append('attack')\n",
    "\n",
    "## add the normal labels\n",
    "for l in range(test_attack.shape[0], test.shape[0]):\n",
    "    testing_labels.append('normal')\n",
    "\n",
    "\n",
    "\n",
    "# train_transition_labels = []\n",
    "## add the transition labels\n",
    "for m in range(0, train_transition.shape[0]):\n",
    "    training_labels.append('transition')\n",
    "\n",
    "# test_transition_labels = []\n",
    "for n in range(0, test_transition.shape[0]):\n",
    "    testing_labels.append('transition')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## create the training and testing data labels\n",
    "## run this cell if using augmented data\n",
    "\n",
    "training_labels = []\n",
    "## add the attack labels\n",
    "for i in range(0, train_attack.shape[0] + vert_flip_train_attack.shape[0] + hor_flip_train_attack.shape[0] + rotate90l_train_attack.shape[0] + rotate90r_train_attack.shape[0]):\n",
    "    training_labels.append('attack')\n",
    "\n",
    "## add the normal labels\n",
    "for j in range(train_attack.shape[0] + vert_flip_train_attack.shape[0] + hor_flip_train_attack.shape[0] + rotate90l_train_attack.shape[0] + rotate90r_train_attack.shape[0], train.shape[0]):\n",
    "    training_labels.append('normal')\n",
    "\n",
    "\n",
    "\n",
    "testing_labels = []\n",
    "## add the attack labels\n",
    "for k in range(0, test_attack.shape[0] + vert_flip_test_attack.shape[0] + hor_flip_test_attack.shape[0] + rotate90l_test_attack.shape[0] + rotate90r_test_attack.shape[0]):\n",
    "    testing_labels.append('attack')\n",
    "\n",
    "## add the normal labels\n",
    "for l in range(test_attack.shape[0] + vert_flip_test_attack.shape[0] + hor_flip_test_attack.shape[0] + rotate90l_test_attack.shape[0] + rotate90r_test_attack.shape[0], test.shape[0]):\n",
    "    testing_labels.append('normal')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## create the training and testing data labels\n",
    "## run this cell if using augmented data but not with rotated data\n",
    "\n",
    "training_labels = []\n",
    "## add the attack labels\n",
    "for i in range(0, train_attack.shape[0] + vert_flip_train_attack.shape[0] + hor_flip_train_attack.shape[0]):\n",
    "    training_labels.append('attack')\n",
    "a\n",
    "## add the normal labels\n",
    "for j in range(train_attack.shape[0] + vert_flip_train_attack.shape[0] + hor_flip_train_attack.shape[0], train.shape[0]):\n",
    "    training_labels.append('normal')\n",
    "\n",
    "\n",
    "\n",
    "testing_labels = []\n",
    "## add the attack labels\n",
    "for k in range(0, test_attack.shape[0] + vert_flip_test_attack.shape[0] + hor_flip_test_attack.shape[0] + rotate90l_train_normal.shape[0] + rotate90r_train_normal.shape[0]):\n",
    "    testing_labels.append('attack')\n",
    "\n",
    "## add the normal labels\n",
    "for l in range(test_attack.shape[0] + vert_flip_test_attack.shape[0] + hor_flip_test_attack.shape[0] + rotate90l_train_normal.shape[0] + rotate90r_train_normal.shape[0], test.shape[0]):\n",
    "    testing_labels.append('normal')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(training_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_labels.extend(train_transition_labels)\n",
    "testing_labels.extend(test_transition_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## create the dataframe for labels, then OHE the column\n",
    "ytrain = pd.DataFrame(training_labels, columns = ['category'])\n",
    "ytest = pd.DataFrame(testing_labels, columns = ['category'])\n",
    "\n",
    "ytrain = pd.get_dummies(ytrain['category'])\n",
    "ytest = pd.get_dummies(ytest['category'])\n",
    "\n",
    "# ytrain, ytest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ytrain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## shuffle the data to prevent pattern recognition\n",
    "train, ytrain = sklearn.utils.shuffle(train, ytrain, random_state = 7)\n",
    "test, ytest = sklearn.utils.shuffle(test, ytest, random_state = 7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "KERNEL_SIZE = [2,2]\n",
    "IMAGE_SIZE = [64,64,1]\n",
    "\n",
    "cnn = Sequential()\n",
    "\n",
    "## convolution 1\n",
    "cnn.add(Conv2D(2**4, (KERNEL_SIZE), padding=\"same\", activation='relu', input_shape = (IMAGE_SIZE)))\n",
    "cnn.add(MaxPooling2D(pool_size = (2,2)))\n",
    "# cnn.add(Dropout(0.25))\n",
    "\n",
    "## convolution 2\n",
    "cnn.add(Conv2D(2**5, (KERNEL_SIZE), padding=\"same\", activation='relu'))\n",
    "cnn.add(MaxPooling2D(pool_size = (2,2)))\n",
    "# cnn.add(Dropout(0.25))\n",
    "\n",
    "## convolution 3\n",
    "cnn.add(Conv2D(2**6, (KERNEL_SIZE), padding=\"same\", activation='relu'))\n",
    "cnn.add(MaxPooling2D(pool_size = (2,2)))\n",
    "# cnn.add(Dropout(0.25))\n",
    "\n",
    "## convolution 4\n",
    "cnn.add(Conv2D(2**7, (KERNEL_SIZE), padding=\"same\", activation='relu'))\n",
    "cnn.add(MaxPooling2D(pool_size = (2,2)))\n",
    "# cnn.add(Dropout(0.5))\n",
    "\n",
    "## convolution 5\n",
    "# cnn.add(Conv2D(128, (KERNEL_SIZE), padding=\"same\", activation='relu'))\n",
    "# cnn.add(MaxPooling2D(pool_size = (2,2)))\n",
    "# # cnn.add(Dropout(0.5))\n",
    "\n",
    "# ## convolution 6\n",
    "# cnn.add(Conv2D(128, (KERNEL_SIZE), padding=\"same\", activation='relu'))\n",
    "# cnn.add(AveragePooling2D(pool_size = (2,2)))\n",
    "# cnn.add(Dropout(0.5))\n",
    "\n",
    "cnn.add(Flatten())\n",
    "\n",
    "## dense\n",
    "# cnn.add(Dense(256, activation='relu'))\n",
    "cnn.add(Dense(128, activation='relu'))\n",
    "# cnn.add(Dense(64, activation='relu'))\n",
    "# cnn.add(Dense(256, activation='relu'))\n",
    "# cnn.add(Dropout(0.5))\n",
    "cnn.add(Dense(3, activation = 'sigmoid'))\n",
    "\n",
    "# callback = [EarlyStopping(monitor = 'accuracy', mode = 'max', patience = 2)]\n",
    "\n",
    "cnn.compile(optimizer = keras.optimizers.Adam(), loss = 'binary_crossentropy',\n",
    "            metrics = ['accuracy'])\n",
    "\n",
    "\n",
    "cnn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "model_history = cnn.fit(train, ytrain, batch_size = 128, epochs = 250) ## smaller batch 128-256, 200-250 epochs\n",
    "end = time.time()\n",
    "\n",
    "os.system(f'say \"training finished in {round(end - start, 2)} seconds\"')\n",
    "print(f'Training finished in {round(end - start, 2)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model_history.history.keys())\n",
    "\n",
    "fig, axes = plt.subplots(nrows=1, ncols=2, figsize=(50,12))\n",
    "fig.suptitle('Training Accuracy and Loss Scores', fontsize = 26)\n",
    "\n",
    "axes[0].plot(model_history.history['acc'])\n",
    "# axes[0].plot(model_history.history['val_acc'])\n",
    "axes[0].set_title('Accuracy', fontsize = 18)\n",
    "axes[0].set_ylabel('Accuracy', fontsize = 16)\n",
    "axes[0].set_xlabel('Epochs', fontsize = 16)\n",
    "axes[0].set_xticks(np.arange(0, 260, step = 10))\n",
    "axes[0].grid(axis = 'x')\n",
    "axes[0].legend(['Train', 'Test'], loc = 'best', fontsize = 18)\n",
    "\n",
    "axes[1].plot(model_history.history['loss'])\n",
    "# axes[1].plot(model_history.history['val_loss'])\n",
    "axes[1].set_title('Loss', fontsize = 18)\n",
    "axes[1].set_ylabel('Loss', fontsize = 16)\n",
    "axes[1].set_xlabel('Epochs', fontsize = 16)\n",
    "axes[1].set_xticks(np.arange(0, 260, step = 10))\n",
    "axes[1].grid(axis = 'x')\n",
    "axes[1].legend(['Train', 'Test'], loc = 'best', fontsize = 18)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss, acc = cnn.evaluate(test, ytest, batch_size = 128, verbose = 0)\n",
    "print(f'Loss = {round(loss, 4)}\\tAccuracy = {round(acc, 4)*100}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = cnn.predict(test)\n",
    "y_preds = np.argmax(preds, axis = 1)\n",
    "\n",
    "print('\\t Attack\\t Normal')\n",
    "preds[:20]*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_classifier():\n",
    "    \n",
    "    cnn = Sequential()\n",
    "\n",
    "    ## convolution 1\n",
    "    cnn.add(Conv2D(2**4, (KERNEL_SIZE), padding=\"same\", activation='relu', input_shape = (IMAGE_SIZE)))\n",
    "    cnn.add(MaxPooling2D(pool_size = (2,2)))\n",
    "    # cnn.add(Dropout(0.5))\n",
    "\n",
    "    ## convolution 2\n",
    "    cnn.add(Conv2D(2**5, (KERNEL_SIZE), padding=\"same\", activation='relu'))\n",
    "    cnn.add(MaxPooling2D(pool_size = (2,2)))\n",
    "    # cnn.add(Dropout(0.5))\n",
    "\n",
    "    ## convolution 3\n",
    "    cnn.add(Conv2D(2**6, (KERNEL_SIZE), padding=\"same\", activation='relu'))\n",
    "    cnn.add(MaxPooling2D(pool_size = (2,2)))\n",
    "    # cnn.add(Dropout(0.5))\n",
    "\n",
    "    ## convolution 4\n",
    "    cnn.add(Conv2D(2**7, (KERNEL_SIZE), padding=\"same\", activation='relu'))\n",
    "    cnn.add(MaxPooling2D(pool_size = (2,2)))\n",
    "    # # cnn.add(Dropout(0.5))\n",
    "    \n",
    "    ## convolution 4\n",
    "#     cnn.add(Conv2D(2**6, (KERNEL_SIZE), padding=\"same\", activation='relu'))\n",
    "#     cnn.add(MaxPooling2D(pool_size = (2,2)))\n",
    "    # # cnn.add(Dropout(0.5))\n",
    "\n",
    "    cnn.add(Flatten())\n",
    "\n",
    "    ## dense\n",
    "#     cnn.add(Dense(256, activation='relu'))\n",
    "    cnn.add(Dense(128, activation='relu'))\n",
    "#     cnn.add(Dense(128, activation='relu'))\n",
    "#     cnn.add(Dense(64, activation='relu'))\n",
    "#     cnn.add(Dropout(0.5))\n",
    "    cnn.add(Dense(2, activation = 'sigmoid'))\n",
    "\n",
    "    # callback = [EarlyStopping(monitor = 'accuracy', mode = 'max', patience = 2)]\n",
    "\n",
    "    cnn.compile(optimizer = keras.optimizers.Adam(), loss = 'binary_crossentropy',\n",
    "                metrics = ['accuracy'])\n",
    "    \n",
    "    return cnn\n",
    "\n",
    "classifier = KerasClassifier(build_fn = build_classifier, batch_size = 128, epochs = 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "\n",
    "kf = KFold(n_splits = 5, random_state = None)\n",
    "score = cross_val_score(classifier, test, ytest, cv = kf)\n",
    "print(f'Model Cross Validation: \\n{round(score.mean(), 3)*100}%')\n",
    "print(f'Model Cross Validation: \\n{score}')\n",
    "\n",
    "os.system('say \"cross validation finished\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
